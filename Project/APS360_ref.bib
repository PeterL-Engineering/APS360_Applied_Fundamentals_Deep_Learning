@article{zhang2016colorful,
  title={Colorful image colorization},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A},
  journal={European conference on computer vision},
  year={2016},
  publisher={Springer}
}

@misc{zhang2017realtime,
  title={Real-Time User-Guided Image Colorization with Learned Deep Priors},
  author={Zhang, Richard and Zhu, Jun-Yan and Isola, Phillip and Geng, Xinyang and Lin, Angela S. and Yu, Tianhe and Efros, Alexei A.},
  year={2017},
  eprint={1705.02999},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/1705.02999}
}

@article{zeger2021grayscale,
  author = {Z{\v{e}}ger, Ivana and Grgic, Sonja and Vukovi{\'c}, Josip and {\v{S}}i{\v{s}}ul, Gordan},
  title={Grayscale Image Colorization Methods: Overview and Evaluation},
  journal={IEEE Access},
  year={2021},
  volume={9},
  pages={113326--113346},
  doi={10.1109/ACCESS.2021.3104515},
  keywords={Image color analysis; Deep learning; Gray-scale; Image quality; Indexes; Image segmentation; Automatic methods; black-and-white image; colorfulness; colorization; deep learning methods; example-based methods; grayscale image; image quality assessment; scribble-based methods; user-guided methods}
}

@incollection{noaman2022image,
  author = {Noaman, M.H. and Khaled, H. and Faheem, H.M.},
  title = {Image Colorization: A Survey of Methodologies and Techniques},
  booktitle = {Proceedings of the International Conference on Advanced Intelligent Systems and Informatics 2021 (AISI 2021)},
  editor = {Hassanien, A.E. and Snášel, V. and Chang, K.C. and Darwish, A. and Gaber, T.},
  year = {2022},
  publisher = {Springer, Cham},
  series = {Lecture Notes on Data Engineering and Communications Technologies},
  volume = {100},
  pages = {123--133},
  doi = {10.1007/978-3-030-89701-7_11},
  url = {https://doi.org/10.1007/978-3-030-89701-7_11}
}

@inproceedings{agrawal2024image,
  author = {Agrawal, Poorva and Mahajan, Shriniwas and Kadu, Varun and Rakesh, Nitin and Parvathi, R. and Kaur, Gagandeep},
  title = {Image Colorization: Comprehensive Review},
  booktitle = {2024 First International Conference on Technological Innovations and Advance Computing (TIACOMP)},
  year = {2024},
  pages = {529--535},
  doi = {10.1109/TIACOMP64125.2024.00093},
  keywords = {Deep learning; Representation learning; Visualization; Technological innovation; Reviews; Superresolution; Real-time systems; Spatial resolution; Spectral analysis; Residual neural networks; Image colorization; GAN; ANN}
}

@incollection{hertzmann2023image,
  author = {Hertzmann, Aaron and Jacobs, Charles E. and Oliver, Nuria and Curless, Brian and Salesin, David H.},
  title = {Image Analogies},
  booktitle = {Seminal Graphics Papers: Pushing the Boundaries, Volume 2},
  year = {2023},
  publisher = {Association for Computing Machinery},
  pages = {58:1--58:14},
  doi = {10.1145/3596711.3596770},
  url = {https://doi.org/10.1145/3596711.3596770}
}

@inproceedings{Vitoria2020ChromaGAN,
  author    = {Patricia Vitoria and Lara Raad and Coloma Ballester},
  title     = {{ChromaGAN: Adversarial Picture Colorization with Semantic Class Distribution}},
  booktitle = {Proceedings of the 2020 IEEE Winter Conference on Applications of Computer Vision (WACV)},
  year      = {2020},
  pages     = {2434--2443},
  publisher = {IEEE Computer Society},
  address   = {Los Alamitos, CA, USA},
  month     = mar,
  doi       = {10.1109/WACV45572.2020.9093389},
  url       = {https://doi.ieeecomputersociety.org/10.1109/WACV45572.2020.9093389},
  abstract  = {The colorization of grayscale images is an ill-posed problem, with multiple correct solutions. In this paper, we propose an adversarial learning colorization approach coupled with semantic information. A generative network is used to infer the chromaticity of a given grayscale image conditioned to semantic clues. This network is framed in an adversarial model that learns to colorize by incorporating perceptual and semantic understanding of color and class distributions. The model is trained via a fully self-supervised strategy. Qualitative and quantitative results show the capacity of the proposed method to colorize images in a realistic way achieving state-of-the-art results.},
  keywords  = {Image color analysis; Semantics; Gray-scale; Gallium nitride; Color; Generators; Task analysis}
}

@article{Iizuka2016Colorization,
  author    = {Satoshi Iizuka and Edgar Simo-Serra and Hiroshi Ishikawa},
  title     = {Let There Be Color! Joint End-to-End Learning of Global and Local Image Priors for Automatic Image Colorization with Simultaneous Classification},
  journal   = {ACM Transactions on Graphics (TOG)},
  volume    = {35},
  number    = {4},
  articleno = {110},
  pages     = {110:1--110:11},
  year      = {2016},
  month     = jul,
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/2897824.2925974},
  url       = {https://doi.org/10.1145/2897824.2925974},
  issn      = {0730-0301},
  abstract  = {We present a novel technique to automatically colorize grayscale images that combines both global priors and local image features. Based on Convolutional Neural Networks, our deep network features a fusion layer that allows us to elegantly merge local information dependent on small image patches with global priors computed using the entire image. The entire framework, including the global and local priors as well as the colorization model, is trained in an end-to-end fashion. Furthermore, our architecture can process images of any resolution, unlike most existing approaches based on CNN. We leverage an existing large-scale scene classification database to train our model, exploiting the class labels of the dataset to more efficiently and discriminatively learn the global priors. We validate our approach with a user study and compare against the state of the art, where we show significant improvements. Furthermore, we demonstrate our method extensively on many different types of images, including black-and-white photography from over a hundred years ago, and show realistic colorizations.},
  keywords  = {colorization, convolutional neural network}
}

@misc{su2020instanceawareimagecolorization,
      title={Instance-aware Image Colorization}, 
      author={Jheng-Wei Su and Hung-Kuo Chu and Jia-Bin Huang},
      year={2020},
      eprint={2005.10825},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2005.10825}, 
}

 @misc{scienceandmediamuseum2020, 
  title={A short history of colour photography}, 
  url={https://www.scienceandmediamuseum.org.uk/objects-and-stories/history-colour-photography}, 
  author={National Science and Media Museum}, 
  year={2020}, 
  month={Jul} 
 }

@article{vogelsang2024impact
  author = {Marin Vogelsang  and Lukas Vogelsang  and Priti Gupta  and Tapan K. Gandhi  and Pragya Shah  and Piyush Swami  and Sharon Gilad-Gutnick  and Shlomit Ben-Ami  and Sidney Diamond  and Suma Ganesh  and Pawan Sinha },
  title = {Impact of early visual experience on later usage of color cues},
  journal = {Science},
  volume = {384},
  number = {6698},
  pages = {907-912},
  year = {2024},
  doi = {10.1126/science.adk9587},
  URL = {https://www.science.org/doi/abs/10.1126/science.adk9587}
}

@misc{cheng2016deepcolorization,
  title={Deep Colorization}, 
  author={Zezhou Cheng and Qingxiong Yang and Bin Sheng},
  year={2016},
  eprint={1605.00075},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/1605.00075}, 
}