\documentclass{article} % For LaTeX2e
\usepackage{iclr2022_conference,times}
% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

%######## APS360: Uncomment your submission name
\newcommand{\apsname}{Project Proposal}
%\newcommand{\apsname}{Progress Report}
%\newcommand{\apsname}{Final Report}

%######## APS360: Put your Group Number here
\newcommand{\gpnumber}{40}

\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}

%######## APS360: Put your project Title here
\title{Image Colourization via Convolutional \\
Neural Networks and Deep Learning}


%######## APS360: Put your names, student IDs and Emails here
\author{Youssef Fikry  \\
Student\# 1005678901\\
\texttt{youssef.fikry@mail.utoronto.ca} \\
\And
Harkirpa Kaur  \\
Student\# 1011242479 \\
\texttt{  harkirpa.kaur@mail.utoronto.ca} \\
\AND
Peter Leong \\
Student\# 1005678901 \\
\texttt{peter.leong@mail.utoronto.ca} \\
\And
Thulasi Thavarajah \\
Student\# 10115358424 \\
\texttt{t.thavarajah@mail.utoronto.ca} \\
\AND
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy 
%######## APS360: Document starts here
\begin{document}


\maketitle

\begin{abstract}
This template should be used for all your project related reports in APS360 course. -- Write an abstract for your project here. Please review the \textbf{ First Course Tutorial} for a quick start
%######## APS360: Do not change the next line. This shows your Main body page count.
----Total Pages: \pageref{last_page}
\end{abstract}



\section{Introduction}

While the colour photography processes first emerged in the 1890s, colour photography did not become widely accessible until the 1970s \cite{scienceandmediamuseum2020}. As a result, 
most historic photographs are black and white and lack the visual richness that modern viewers are accustomed to. In addition, individuals who have their cataracts 
removed as a part of vision restoration processes have shown to struggle with identifying objects in black and white images \cite{vogelsang2024impact}, making most historic photographs 
inaccessible to them. This project aims to use deep learning to automatically colorize black and white images, with the goal of restoring visual information and 
making historical imagery more accessible for all audiences. Traditional, non deep-learning based colorization methods often produce desaturated results and rely 
heavily on human guidance \cite{cheng2016deepcolorization}, making them non-scalable. Conversely, deep networks such as CNNs effectively capture spatial and semantic features and produce 
realistic colourized images without user interaction \cite{zhang2016colorful}, making deep learning an ideal approach for image colorization.

\subsection{Background \& Related Work}

The challenge of image colourization has been approached in a wide variety of ways. Even within solutions involving deep learning
techniques, there numerous unique design choices. One grouping method \cite{zeger2021grayscale} results in five categories: simple colourization neural networks,
user-guided colourization neural networks, diverse colourization neural networks, multi-path colourization neural networks, and examplar-based
neural networks. 

Simple colourization neural networks use feedforward CNNs to map grayscale inputs to colour outputs. One of the foremost solutions proposed by 
\cite{zhang2016colorful} used a fully convolutional network to predict the a and b channels of the CIELAB colour space from grayscale images. Their 
architecture is composed of several convulational layers, each followed by a ReLU activation function and a batch normailization layer.

User-guided colourization neural networks use user input to guide the colourization process. One such solution \cite{zhang2017real} uses a
fully convolutional network to predict the a and b channels of the CIELAB colour space from grayscale images, but also takes user input in the form of
user-provided colour scribbles. The network is trained to minimize the difference between the predicted and user-provided colours, allowing it to
learn to colourize images in a way that is consistent with the user's input. 

Diverse colourization networks produce multiple colourization outputs for a given grayscale input. One such solution \cite{Vitoria2020ChromaGAN} uses
a generative adversarial network (GAN) to produce multiple colourization outputs for a given grayscale input. The GAN is trained to minimize the difference
between the predicted and ground truth colours, allowing it to learn to produce diverse colourization outputs. 

Multi-path colourization neural networks differentiate features at different scales. \cite{Iizuka2016Colourization} proposed a multi-path
colourization neural network that uses multiple convolutional layers to extract features at different scales. The network is trained to minimize the difference
between the predicted and ground truth colours, allowing it to learn to produce colourization outputs that are consistent with the features at different scales. 

Exemplar-based neural networks use a set of exemplar images to guide the colourization process. In \cite{su2020instanceawareimagecolorization}, example images are
used to trasnfer the colour to the target image. Each instance is ouput to two different colourization networks which fuse to yield the final result. This group of 
solutions is easier to implement, as learning to colourize instances is significantly easier than learning to colourize an entire image. 

\section{Methodology}
\label{methodology}

\subsection{Data Processing}

\subsection{Architecture}

\subsection{Baseline Model}

\section{Ethical Considerations}
\label{ethical}

The dataset being used is public, so there are no copyright or consent issues. However, the dataset may contain racial or demographic imbalances, which could cause the model 
to generalize poorly or be biased towards specific skin tones. This may result in racially inaccurate or culturally insensitive outputs. A similar behaviour may be observed with 
animals, where a lack of diversity in breeds or fur colours in the dataset can result in misleading results. If the outputs produced by the model are used in educational contexts 
or in breed identification, they can contribute to misinformation. Furthermore, since the model results are plausible but cannot be verified, there is a risk that users may 
overtrust the outputs in sensitive contexts.

\section{Project Plan}
\label{project_plan}

\subsection{Team Communication \& Coordination}

\section{Risk Register}
\label{risk_register}

\label{last_page}

\bibliography{APS360_ref}
\bibliographystyle{iclr2022_conference}

\end{document}
